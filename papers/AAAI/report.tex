% File: report.tex

\documentclass[letterpaper]{article}
\usepackage{aaai}
\usepackage{times}
\usepackage{helvet}
\usepackage{courier}
\frenchspacing
\pdfoutput=1
\pdfinfo{
/Title (Primitive Recognition using Inverse Q-Table Matching)
/Subject (In Proceedings AAAI)
/Author (Bradley Hayes, Brian Scassellati, and Thaddeus Diamond)
}
  
\begin{document}
\title{Scene Decomposition using Inverse Q-Table Matching}
\author{Bradley Hayes, Brian Scassellati, and Thaddeus Diamond\\
Yale University\\
Arthur K. Watson Hall\\
51 Prospect St\\
New Haven, Connecticut 06511\\
}

\maketitle

\begin{abstract}
Primitive skill acquisition for robots has been accomplished through a variety
of techniques, many utilizing Q-Learning. Recent work has shown that with human
assistance, complex actions can be learned with limited training data. The
resulting skill representations can be leveraged to replay flexible behaviors
that dramatically increase the utility of the robot. Despite this, existing
systems have yet to address the greater problem of cooperative action execution.
For a robot to effectively cooperate with either human or robotic coworkers,
it is necessary that the robot be capable of modeling and recognizing its
coworkerâ€™s behaviors within its environment. We approach the task of
understanding and predicting coworker actions by providing a real-time method
allowing a robot to solve the inverse problem of skill execution: skill
recognition. We demonstrate our results through the recognition of selected
American Sign Language gestures. Our algorithm provides a coded timeline of
primitive actions generated in real-time, correcting its hypotheses as more
information is presented. This data can then be directly used in a multitude
of ways, from within a planning system for the coordination of a robot's
actions within its space to building a skill hierarchy fully
decomposing a complex cooperative task into primitive actions.
\end{abstract}

\section{Introduction}
\label{sec:intro}
Empirical data has consistently proven that reinforcement learning can be used
as a viable method to learn primitive skills in a real robotic systems.
Standard Q-Learning techniques which traditionally take several hundred or
several thousand trials to converge on a learned skill have been supplanted
by techniques yielding convergent results within some small margin of error,
which require orders of magnitude fewer trials.   Although there are too many
to enumerate here, some of the techniques include the use of simple external
feedback such as "good" and "bad" indicators \cite{TAMER} or an animal
clicker \cite{Clicker}, the use of intermittent human
guidance \cite{AdviceTaking,TeacherRL}, and the integration of human
demonstration \cite{DemonstrationRL}.  These results
have made compelling the use of modified Q-Learning in real robotic systems.

Very little work has focused on using data gathered during the Q-Learning
process to later decompose a complex scene into a set of primitives via
observation.  The concept of "inverse reinforcement learning" is not entirely
novel, as Abbeel and Ng \cite{InverseRL} used inverse reinforcement learning
to generate reasonable approximations for the reward function underlying an
observed primitive.  However, their work does not leverage existing data
to create approximate classifications, but rather uses raw sensory data to
attempt to recover the unknown reward function.

We present herein a system that, using Q-Tables generated from simple
Q-Learning in a real robotic system, uses observation to 
It is important to separate the context of our contribution from that of
existing research in \textit{learning from demonstration} (LfD).  Standard
techniques in reinforcement learning have focused on using examples to
transfer a policy representing some basic skill from a teacher to a
pupil \cite{JenkinsLFD,LFDSurvey}.  We focus on the use of
\textit{existing knowledge} to generate an approximate decomposition of
complex scene data.

\section{Background}
\label{sec:background}
\subsection{American Sign Language Gesture Recognition}
The domain in which we test our system is American Sign Language (ASL).
American sign language is chosen as a domain in which to test our scheme
because each motion involves six degrees of freedom -- the x, y, and z
coordinates of each hand relative to the agent's head -- which creates a
state space sufficiently large enough to preclude achieving real-time
optimality via na\"ive brute force methods.  The
robotic system has a priori knowledge of a set of ASL gestures and the
corresponding Q-Table.

Gesture recognition is not a novel concept.  Something about gesture recognition
here...\cite{HandGestures}\cite{HSMMRecognition}\cite{POMDPGesture}.
Several works have already provided robust gesture recognition systems for
ASL \cite{HoughASL}\cite{ASLRealTime}\cite{MotionASL}.

\subsection{Hierarchical Task Decomposition}
\cite{Hierarchical}

\section{Primitive Recognition}
\label{sec:recognition}
In this section we discuss our work on primitive recognition.

\section{Results}
\label{sec:result}
In this section we discuss our experimental results.

\section{Related and Future Work}
\label{sec:future}
In this section we discuss future work (hint at SHL?)

\section{Conclusions}
\label{sec:conclusions}
In this section we conclude.

\section{Acknowledgements}
\label{sec:acknowledgements}
We would like to thank... grant numbers?  Brad's grad school funding?  God?
Wayne Brady?

\bibliography{report}
\bibliographystyle{aaai}

\end{document}attempt 
